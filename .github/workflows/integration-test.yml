name: Integration Test - DocumentDB Operator

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  packages: write
  contents: read
  id-token: write

env:
  # Cluster configuration
  CERT_MANAGER_NS: cert-manager
  OPERATOR_NS: documentdb-operator
  DB_NS: documentdb-preview-ns
  DB_NAME: documentdb-preview
  # Connection parameters
  DB_USERNAME: default_user
  DB_PASSWORD: Admin100
  DB_PORT: 10260

jobs:
  # Use the reusable build workflow
  build:
    name: Build Images and Charts
    uses: ./.github/workflows/build-and-package.yml
    with:
      image_tag_prefix: 'integration-test'
      chart_version_prefix: '0.1.0'
      push_to_registry: true
    secrets: inherit

  integration-test:
    runs-on: ${{ matrix.runner }}
    timeout-minutes: 45
    needs: build
    
    strategy:
      matrix:
        include:
          - architecture: amd64
            runner: ubuntu-latest
          # - architecture: arm64
          #   runner: ubuntu-22.04-arm
    
    env:
      # Use outputs from the build workflow
      IMAGE_NAME: documentdb-kubernetes-operator
      IMAGE_TAG: ${{ needs.build.outputs.image_tag }}
      CHART_VERSION: ${{ needs.build.outputs.chart_version }}
      ARCHITECTURE: ${{ matrix.architecture }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y jq curl netcat-openbsd

    - name: Install Helm
      uses: azure/setup-helm@v3

    - name: Create kind cluster
      uses: helm/kind-action@v1.8.0
      with:
        cluster_name: documentdb-test-${{ matrix.architecture }}

    - name: Install dependencies
      run: |
        echo "Installing dependencies for ${{ matrix.architecture }} architecture..."
        
        # Install MongoDB shell - use architecture-appropriate method
        if [[ "${{ matrix.architecture }}" == "arm64" ]]; then
          # For ARM64, we may need to use different installation method
          curl -fsSL https://pgp.mongodb.com/server-7.0.asc | sudo gpg --dearmor -o /usr/share/keyrings/mongodb-server-7.0.gpg
          echo "deb [ arch=arm64 signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list
        else
          # For AMD64
          curl -fsSL https://pgp.mongodb.com/server-7.0.asc | sudo gpg --dearmor -o /usr/share/keyrings/mongodb-server-7.0.gpg
          echo "deb [ arch=amd64 signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list
        fi
        
        sudo apt-get update && sudo apt-get install -y mongodb-mongosh
        
        # Verify installation
        mongosh --version
        echo "✓ mongosh installed successfully for ${{ matrix.architecture }}"

    - name: Setup cluster
      run: |
        echo "Setting up cluster on ${{ matrix.architecture }} architecture..."
        kubectl wait --for=condition=Ready nodes --all --timeout=300s
        
        # Verify node architecture
        kubectl get nodes -o wide
        echo "Node architecture verification:"
        kubectl get nodes -o jsonpath='{.items[*].status.nodeInfo.architecture}'
        echo ""
        
        helm repo add jetstack https://charts.jetstack.io && helm repo update
        helm install cert-manager jetstack/cert-manager \
          --namespace $CERT_MANAGER_NS --create-namespace \
          --set installCRDs=true --wait --timeout=5m
        
        # Login to GHCR for Helm
        echo "${{ secrets.GITHUB_TOKEN }}" | helm registry login ghcr.io --username ${{ github.actor }} --password-stdin
        
        # Install the operator using the newly created chart
        helm install documentdb-operator oci://ghcr.io/${{ github.repository_owner }}/documentdb-operator \
          --version ${{ env.CHART_VERSION }} --namespace $OPERATOR_NS --create-namespace --wait --timeout=8m
        
        echo "✓ Cluster setup completed on ${{ matrix.architecture }}"

    - name: Deploy DocumentDB cluster
      run: |
        echo "Deploying DocumentDB cluster on ${{ matrix.architecture }} architecture..."
        
        cat <<EOF | kubectl apply -f -
        apiVersion: v1
        kind: Namespace
        metadata:
          name: ${DB_NS}
        ---
        apiVersion: db.microsoft.com/preview
        kind: DocumentDB
        metadata:
          name: ${DB_NAME}
          namespace: ${DB_NS}
        spec:
          nodeCount: 1
          instancesPerNode: 1
          documentDBImage: ghcr.io/microsoft/documentdb/documentdb-local:16
          resource:
            pvcSize: 5Gi
          publicLoadBalancer:
            enabled: false
        EOF
        
        echo "DocumentDB resource created on ${{ matrix.architecture }}, waiting for cluster to be ready..."
        
        sleep 30
        
        timeout 600 bash -c '
        while true; do
          echo "Checking for DocumentDB pods..."
          kubectl get pods -n '$DB_NS' || true
          
          pod_count=$(kubectl get pods -n '$DB_NS' -l cnpg.io/cluster='$DB_NAME' --no-headers 2>/dev/null | wc -l)
          if [[ "$pod_count" -eq "0" ]]; then
            echo "No DocumentDB pods found yet, waiting..."
            sleep 15
            continue
          fi
          
          ready=$(kubectl get pods -n '$DB_NS' -l cnpg.io/cluster='$DB_NAME' -o json | jq ".items[] | select(.status.phase == \"Running\" and ([.status.containerStatuses[] | .ready] | all))" | jq -s "length")
          if [[ "$ready" -eq "1" ]]; then
            echo "DocumentDB cluster is ready!"
            break
          fi
          echo "Waiting for pods to be ready... ($ready/1 pods ready)"
          sleep 15
        done'
        
        echo "Final pod status on ${{ matrix.architecture }}:"
        kubectl get pods -n $DB_NS -o wide

    - name: Test connection with mongosh
      run: |
        echo "Testing connection with mongosh on ${{ matrix.architecture }} architecture..."
        
        # Start port-forward in background
        kubectl port-forward pod/${DB_NAME}-1 $DB_PORT:$DB_PORT -n $DB_NS &
        PF_PID=$!
        
        # Wait for port-forward to be ready
        sleep 10
        
        # Test connection and run basic operations
        timeout 60 bash -c '
        until nc -z 127.0.0.1 '$DB_PORT'; do
          echo "Waiting for port-forward to be ready..."
          sleep 2
        done
        '
        
        echo "Port-forward is ready, testing mongosh connection..."
        
        # Create test script with validation
        cat > test_mongosh.js << 'EOF'
        // Test basic connection and operations
        print("Connected to DocumentDB!");
        
        // Switch to test database
        db = db.getSiblingDB('testdb');
        
        // Create collection and insert test data
        db.createCollection("test_collection");
        
        var result = db.test_collection.insertMany([
          { name: "Alice", age: 30, department: "Engineering" },
          { name: "Bob", age: 25, department: "Marketing" },
          { name: "Charlie", age: 35, department: "Sales" }
        ]);
        
        print("Inserted documents:", result.insertedIds);
        
        // Validate insertion - check we got 3 documents
        var insertedCount = Object.keys(result.insertedIds).length;
        if (insertedCount !== 3) {
          throw new Error("Expected 3 inserted documents, got " + insertedCount);
        }
        print("✓ Insertion validation passed");
        
        // Query the data and validate count
        var docs = db.test_collection.find().toArray();
        print("Found documents:", docs.length);
        if (docs.length !== 3) {
          throw new Error("Expected 3 documents in collection, found " + docs.length);
        }
        print("✓ Document count validation passed");
        
        // Validate document content
        var alice = docs.find(doc => doc.name === "Alice");
        var bob = docs.find(doc => doc.name === "Bob");
        var charlie = docs.find(doc => doc.name === "Charlie");
        
        if (!alice || alice.age !== 30 || alice.department !== "Engineering") {
          throw new Error("Alice document validation failed: " + JSON.stringify(alice));
        }
        if (!bob || bob.age !== 25 || bob.department !== "Marketing") {
          throw new Error("Bob document validation failed: " + JSON.stringify(bob));
        }
        if (!charlie || charlie.age !== 35 || charlie.department !== "Sales") {
          throw new Error("Charlie document validation failed: " + JSON.stringify(charlie));
        }
        print("✓ Document content validation passed");
        
        // Test aggregation and validate result
        var avgAge = db.test_collection.aggregate([
          { $group: { _id: null, avgAge: { $avg: "$age" } } }
        ]).toArray();
        
        print("Average age:", avgAge[0].avgAge);
        var expectedAvgAge = (30 + 25 + 35) / 3; // 30
        if (Math.abs(avgAge[0].avgAge - expectedAvgAge) > 0.01) {
          throw new Error("Expected average age " + expectedAvgAge + ", got " + avgAge[0].avgAge);
        }
        print("✓ Aggregation validation passed");
        
        // Test update and validate
        var updateResult = db.test_collection.updateOne(
          { name: "Alice" },
          { $set: { title: "Senior Engineer" } }
        );
        
        print("Update result:", JSON.stringify(updateResult));
        print("Modified count:", updateResult.modifiedCount);
        print("Matched count:", updateResult.matchedCount);
        print("Acknowledged:", updateResult.acknowledged);
        
        if (updateResult.modifiedCount != 1) {
          throw new Error("Expected 1 modified document, got " + updateResult.modifiedCount + " (type: " + typeof updateResult.modifiedCount + ")");
        }
        print("✓ Update operation validation passed");
        
        // Verify update content
        var aliceUpdated = db.test_collection.findOne({ name: "Alice" });
        print("Alice after update:", aliceUpdated);
        
        if (!aliceUpdated.title || aliceUpdated.title !== "Senior Engineer") {
          throw new Error("Alice title update validation failed: " + JSON.stringify(aliceUpdated));
        }
        if (aliceUpdated.age !== 30 || aliceUpdated.department !== "Engineering") {
          throw new Error("Alice other fields changed unexpectedly: " + JSON.stringify(aliceUpdated));
        }
        print("✓ Update content validation passed");
        
        // Test query with filters
        var engineers = db.test_collection.find({ department: "Engineering" }).toArray();
        if (engineers.length !== 1 || engineers[0].name !== "Alice") {
          throw new Error("Department filter validation failed: " + JSON.stringify(engineers));
        }
        print("✓ Query filter validation passed");
        
        // Test sorting
        var sortedByAge = db.test_collection.find().sort({ age: 1 }).toArray();
        if (sortedByAge[0].name !== "Bob" || sortedByAge[1].name !== "Alice" || sortedByAge[2].name !== "Charlie") {
          throw new Error("Sort validation failed: " + JSON.stringify(sortedByAge.map(d => d.name)));
        }
        print("✓ Sort validation passed");
        
        print("All mongosh tests passed with validation!");
        EOF
        
        # Run the test and validate it succeeds
        echo "Running mongosh validation tests..."
        if mongosh 127.0.0.1:$DB_PORT \
          -u $DB_USERNAME \
          -p $DB_PASSWORD \
          --authenticationMechanism SCRAM-SHA-256 \
          --tls \
          --tlsAllowInvalidCertificates \
          --file test_mongosh.js; then
          echo "✓ Mongosh validation tests completed successfully on ${{ matrix.architecture }}"
        else
          echo "❌ Mongosh validation tests failed on ${{ matrix.architecture }}"
          exit 1
        fi
        
        # Clean up port-forward
        kill $PF_PID || true

    - name: Test with Python PyMongo client
      run: |
        echo "Testing with Python PyMongo client on ${{ matrix.architecture }} architecture..."
        
        # Install Python dependencies
        pip install pymongo
        
        # Start port-forward in background
        kubectl port-forward pod/${DB_NAME}-1 $DB_PORT:$DB_PORT -n $DB_NS &
        PF_PID=$!
        
        # Wait for port-forward to be ready
        sleep 10
        
        # Test connection and ensure port-forward is ready
        timeout 60 bash -c '
        until nc -z 127.0.0.1 '$DB_PORT'; do
          echo "Waiting for port-forward to be ready..."
          sleep 2
        done
        '
        
        echo "Port-forward is ready, running Python tests..."
        
        # Run the existing Python test script and validate it completes successfully
        cd scripts/test-scripts
        echo "Running existing Python test script on ${{ matrix.architecture }}..."
        if python3 mongo-python-data-pusher.py; then
          echo "✓ Existing Python test script completed successfully on ${{ matrix.architecture }}"
        else
          echo "❌ Existing Python test script failed on ${{ matrix.architecture }}"
          exit 1
        fi
        cd - > /dev/null
        
        # Run additional Python tests with validation
        cat > additional_test.py << 'EOF'
        from pymongo import MongoClient
        import ssl
        import sys

        def validate_test(condition, message):
            if not condition:
                print(f"❌ VALIDATION FAILED: {message}")
                sys.exit(1)
            print(f"✓ {message}")

        # Connection parameters
        client = MongoClient(
            "127.0.0.1",
            10260,
            username="default_user",
            password="Admin100",
            authSource="admin",
            authMechanism="SCRAM-SHA-256",
            tls=True,
            tlsAllowInvalidCertificates=True
        )

        # Test database operations
        test_db = client["integration_test"]
        
        # Test collection operations
        collection = test_db["test_collection"]
        
        # Clear any existing data
        collection.drop()
        
        # Insert test data and validate
        docs = [
            {"type": "integration_test", "value": i, "status": "active"}
            for i in range(10)
        ]
        result = collection.insert_many(docs)
        print(f"Inserted {len(result.inserted_ids)} documents")
        
        # Validate insertion
        validate_test(len(result.inserted_ids) == 10, "Inserted exactly 10 documents")
        validate_test(all(isinstance(id, object) for id in result.inserted_ids), "All inserted IDs are valid ObjectIds")
        
        # Test queries and validate results
        count = collection.count_documents({"status": "active"})
        print(f"Found {count} active documents")
        validate_test(count == 10, "Found exactly 10 active documents")
        
        # Test specific value queries
        value_5_docs = list(collection.find({"value": 5}))
        validate_test(len(value_5_docs) == 1, "Found exactly 1 document with value 5")
        validate_test(value_5_docs[0]["value"] == 5, "Document with value 5 has correct value")
        validate_test(value_5_docs[0]["status"] == "active", "Document with value 5 has correct status")
        validate_test(value_5_docs[0]["type"] == "integration_test", "Document with value 5 has correct type")
        
        # Test range queries
        high_value_docs = list(collection.find({"value": {"$gte": 7}}))
        validate_test(len(high_value_docs) == 3, "Found exactly 3 documents with value >= 7")
        expected_values = {7, 8, 9}
        found_values = {doc["value"] for doc in high_value_docs}
        validate_test(found_values == expected_values, f"High value documents have correct values: {found_values}")
        
        # Test aggregation and validate results
        pipeline = [
            {"$match": {"status": "active"}},
            {"$group": {"_id": "$status", "total": {"$sum": "$value"}, "count": {"$sum": 1}}}
        ]
        agg_result = list(collection.aggregate(pipeline))
        print(f"Aggregation result: {agg_result}")
        
        validate_test(len(agg_result) == 1, "Aggregation returned exactly 1 group")
        validate_test(agg_result[0]["_id"] == "active", "Aggregation grouped by 'active' status")
        expected_total = sum(range(10))  # 0+1+2+...+9 = 45
        validate_test(agg_result[0]["total"] == expected_total, f"Aggregation total is correct: {expected_total}")
        validate_test(agg_result[0]["count"] == 10, "Aggregation count is correct: 10")
        
        # Test update operations
        update_result = collection.update_many(
            {"value": {"$lt": 5}},
            {"$set": {"status": "updated"}}
        )
        validate_test(update_result.modified_count == 5, f"Updated exactly 5 documents (got {update_result.modified_count})")
        
        # Validate update results
        updated_docs = list(collection.find({"status": "updated"}))
        validate_test(len(updated_docs) == 5, "Found exactly 5 updated documents")
        updated_values = {doc["value"] for doc in updated_docs}
        expected_updated_values = {0, 1, 2, 3, 4}
        validate_test(updated_values == expected_updated_values, f"Updated documents have correct values: {updated_values}")
        
        # Test that non-updated documents are unchanged
        active_docs = list(collection.find({"status": "active"}))
        validate_test(len(active_docs) == 5, "Found exactly 5 still-active documents")
        active_values = {doc["value"] for doc in active_docs}
        expected_active_values = {5, 6, 7, 8, 9}
        validate_test(active_values == expected_active_values, f"Active documents have correct values: {active_values}")
        
        # Test sorting
        sorted_docs = list(collection.find().sort("value", -1))  # Descending order
        validate_test(len(sorted_docs) == 10, "Sorted query returned all 10 documents")
        sorted_values = [doc["value"] for doc in sorted_docs]
        expected_sorted = list(range(9, -1, -1))  # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
        validate_test(sorted_values == expected_sorted, f"Documents sorted correctly: {sorted_values}")
        
        # Test complex aggregation with multiple stages
        complex_pipeline = [
            {"$match": {"value": {"$gte": 3}}},
            {"$group": {"_id": "$status", "avg_value": {"$avg": "$value"}, "max_value": {"$max": "$value"}}},
            {"$sort": {"_id": 1}}
        ]
        complex_result = list(collection.aggregate(complex_pipeline))
        print(f"Complex aggregation result: {complex_result}")
        
        # Validate complex aggregation
        validate_test(len(complex_result) == 2, "Complex aggregation returned 2 groups (active and updated)")
        
        # Find the results for each status
        active_result = next((r for r in complex_result if r["_id"] == "active"), None)
        updated_result = next((r for r in complex_result if r["_id"] == "updated"), None)
        
        validate_test(active_result is not None, "Found active group in complex aggregation")
        validate_test(updated_result is not None, "Found updated group in complex aggregation")
        
        # For active status: values 5,6,7,8,9 -> avg = 7, max = 9
        validate_test(abs(active_result["avg_value"] - 7.0) < 0.001, f"Active group avg_value is correct: {active_result['avg_value']}")
        validate_test(active_result["max_value"] == 9, f"Active group max_value is correct: {active_result['max_value']}")
        
        # For updated status: values 3,4 (only those >= 3) -> avg = 3.5, max = 4
        validate_test(abs(updated_result["avg_value"] - 3.5) < 0.001, f"Updated group avg_value is correct: {updated_result['avg_value']}")
        validate_test(updated_result["max_value"] == 4, f"Updated group max_value is correct: {updated_result['max_value']}")

        print("All Python integration tests passed with validation!")
        print(f"Test completed successfully on architecture: {sys.platform}")
        
        client.close()
        EOF
        
        echo "Running Python validation tests on ${{ matrix.architecture }}..."
        if python3 additional_test.py; then
          echo "✓ Python validation tests completed successfully on ${{ matrix.architecture }}"
        else
          echo "❌ Python validation tests failed on ${{ matrix.architecture }}"
          exit 1
        fi
        
        # Clean up port-forward
        kill $PF_PID || true

    - name: Collect logs on failure
      if: failure()
      run: |
        echo "=== Collecting diagnostic information for ${{ matrix.architecture }} ==="
        
        # Check if kubectl is working
        if ! kubectl version --client &>/dev/null; then
          echo "kubectl not available"
          exit 0
        fi
        
        # Check if cluster is accessible
        if ! kubectl cluster-info &>/dev/null; then
          echo "Cluster not accessible"
          kubectl config current-context || echo "No kubectl context found"
          kubectl config get-contexts || echo "No contexts available"
          exit 0
        fi
        
        echo "=== Cluster nodes ==="
        kubectl get nodes -o wide || echo "Failed to get nodes"
        
        echo "=== All pods ==="
        kubectl get pods --all-namespaces -o wide || echo "Failed to get pods"
        
        echo "=== DocumentDB resources ==="
        kubectl get documentdb -n $DB_NS -o yaml || echo "Failed to get DocumentDB resources"
        
        echo "=== DocumentDB pod logs ==="
        kubectl logs -n $DB_NS -l cnpg.io/cluster=$DB_NAME --all-containers=true --tail=100 || echo "Failed to get DocumentDB pod logs"
        
        echo "=== DocumentDB pod description ==="
        kubectl describe pods -n $DB_NS -l cnpg.io/cluster=$DB_NAME || echo "Failed to describe DocumentDB pods"
        
        echo "=== Operator logs ==="
        kubectl logs -n $OPERATOR_NS deployment/documentdb-operator --tail=100 || echo "Failed to get operator logs"
        
        echo "=== cert-manager logs ==="
        kubectl logs -n $CERT_MANAGER_NS --all-containers=true --tail=50 || echo "Failed to get cert-manager logs"
        
        echo "=== Events ==="
        kubectl get events --all-namespaces --sort-by='.lastTimestamp' || echo "Failed to get events"
